<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Decoding for Structured Language Models">
  <meta name="keywords" content="CABS, Structure Language Model, Structured Object Decoding, Function Call, JSON generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3YHT6M18Z2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3YHT6M18Z2');
</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Confidence-Aware Sub-Structure Beam Search (CABS): Mitigating Hallucination in Structured Data Generation with Large Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/chengwei-wei-23675a1b3/">Chengwei Wei</a><sup><span>&#9824;</span></sup>,</span>
            <span class="author-block">
              <a href="https://www.amazon.science/author/kee-kiat-koo">Kee Kiat Koo</a></span>,<!--br-->
            <span class="author-block">
              <a href="https://www.amazon.science/author/amir-tavanaei">Amir Tavanaei</a>,
            </span>
            <span class="author-block">
              <a href="https://www.amazon.science/author/karim-bouyarmane">Karim Bouyarmane</a>
            </span>
          </div>

          <div class="is-size-4 publication-authors">
            <span class="author-block new-line"><sup></sup>Amazon</span><br>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block new-line"><sup><span>&#9824;</span> </sup>University of Southern California, work done during internship at Amazon</span><br>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">

              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.00069"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>ArXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.00069"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>
              
              <span class="link-block">
                <a href="./static/videos/CABS_LLM_SHORT.mp4" download
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-download"></i>
                  </span>
                  <span>MP4</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" class="responsive-video" autoplay muted playsinline height="100%" controls>
        <source src="./static/videos/CABS_LLM_SHORT.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) have facilitated structured data generation, with applications in domains like tabular data, document databases, product catalogs, etc. However, concerns persist about generation veracity due to incorrect references or hallucinations, necessitating the incorporation of some form of model confidence for mitigation. Existing confidence estimation methods on LLM generations primarily focus on the confidence at the individual token level or the entire output sequence level, limiting their applicability to structured data generation, which consists of an intricate mix of both independent and correlated entries at the sub-structure level. In this paper, we first investigate confidence estimation methods for generated sub-structure-level data. We introduce the concept of Confidence Network that applies on the hidden state of the LLM transformer, as a more targeted estimate than the traditional token conditional probability. We further propose Confidence-Aware sub-structure Beam Search (CABS), a novel decoding method operating at the sub-structure level in structured data generation. CABS enhances the faithfulness of structured data generation by considering confidence scores from the Confidence Network for each sub-structure-level data and iteratively refining the prompts. Results show that CABS outperforms traditional token-level beam search for structured data generation by 16.7% Recall at 90% precision averagely on the problem of product attribute generation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful, please cite our paper:</p>
    <pre><code>@misc{under review,
      doi = {arXiv:2406.00069},
      url = {https://arxiv.org/pdf/2406.00069},
      author = {Chengwei Wei, Kee Kiat Koo, Amir Tavanaei, Karim Bouyarmane},
      title = {Confidence-Aware Sub-Structure Beam Search (CABS): Mitigating Hallucination in Structured Data Generation with Large Language Models},
      publisher = {ArXiv},
      year = {2024},
      primaryClass={cs.CL}
}</code></pre>
  </div>
</section>
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> and <a href="https://textual-inversion.github.io/"> Textual Inversion</a>  project pages. If you want to reuse it, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
